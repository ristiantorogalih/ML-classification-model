---
title: 'Classification 1 : In-class materials'
author: "Nabiilah Ardini Fauziyyah"
date: "`r format(Sys.Date(), '%B %e, %Y')`"
output:
  html_document:
    theme: cosmo
    highlight: tango
    toc: true
    toc_float:
      collapsed: true
    df_print: paged
    
---

```{r setup, include=FALSE}
# clear-up the environment
rm(list = ls())

# chunk options
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  fig.align = "center",
  comment = "#>")
options(scipen = 9999)

# library
library(dplyr)
```

Klasifikasi bertujuan untuk memprediksi kelas (**target variable kategorik**):

* binary classification: 2 kelas
* multiclass classification: > 2 kelas

# Logistic Regression

## Basic Intuition

### Probability

Pada dasarnya, ketika kita melakukan klasifikasi, kita menghitung **peluang**. 

**Contoh:**

Anda adalah student Algoritma yang akan mengerjakan kuis C1. Pada batch sebelumnya, ada 24 dari 30 student yang berhasil mengerjakan kuis. Apakah Anda akan lulus pada kuis C1 ini?

```{r}
# peluang lulus
24/30
```
```{r}
# peluang tidak lulus
(30-24)/30
```
```{r}
# tentukan kelas
ifelse(0.8 > 0.5, "LULUS", "TIDAK LULUS")
```

kesimpulan: diprediksi lulus

Berapa range peluang?

* min: 0
* max: 1

Berapa range hasil prediksi model regresi?

* min: -inf
* max: inf

Dibutuhkan suatu jembatan agar regression dapat digunakan untuk memprediksi peluang. Jembatan itu adalah **Odds** dan **Log of Odds**.

### Odds & Log of Odds

> Peluang: jumlah kejadian terjadi / total kejadian

Odds adalah bentuk lain dari peluang, yaitu perbandingan peluang antara **peluang kejadian terjadi/peluang kejadian tidak terjadi**.  

$$\frac{p}{(1-p)}$$ 

`p` = peluang suatu kejadian terjadi

**Contoh 1:**

Berapa odds dari Anda lulus mengerjakan kuis C1?

```{r}
# peluang = 0.8
# peluang tidak lulus = 0.2
# odds
0.8/0.2
```

Interpretasi: Kejadian seseorang lulus kuis adalah **4 KALI lebih mungkin** dibandingkan tidak lulus kuis. 

Dapat dianalogikan juga, bila odds = 4 (4:1), maka bila ada 4 orang lulus ada yang 1 tidak lulus.

**Contoh 2:** 

Anda hendak berpergian menggunakan pesawat dari Soekarno Hatta Airport. Bila diketahui dari 100 penerbangan di Soekarno Hatta, terdapat 25 pesawat `Delay`. Berapa odds pesawat Anda `On Time`?

```{r}
# peluang
p <- (100-25)/100
# odds
p/(1-p) #0.75/0.25
```

Interpretasi:

* peluang on time 3x lebih mungkin drpd tidak on time

Note: Kalau oddsnya 1 berarti peluangnya? fifty-fifty (0.5)

Berapa range nilai dari odds? 

```{r}
# odds: p/1-p
# min
0/(1-0)
# max
1/(1-1)
```

* Probability: 0 1
* Odds       : 0 Inf

Log of odds adalah nilai odds yang dilogaritmikkan:

\(logit(p) = log(\frac{p}{1-p})\)

```{r}
# log of odds - lulus kuis
log(4)
# log of odds - pesawat on time
log(3)
```

Berapa range nilai log of odds?

```{r}
# min
log(0/(1-0))
# max
log(1/(1-1))
```

* Probability: 0 1
* Odds       : 0 inf
* Log of odds: -inf inf

* Regresi    : -inf inf

Odds dan log of odds mampu menjembatani antara nilai yang dihasilkan oleh model regresi, ke rentang nilai peluang. **Logistic regression menghasilkan Log of Odds**. Nilai log of odds dapat dikembalikan ke bentuk odds (untuk diinterpretasikan) dan peluang sehingga dapat digunakan untuk klasifikasi.

```{r}
# log of odds -> odds
odds <- exp(1.386294) # untuk merubah nilai log ke nilai aslinya bisa menggunakan exponen
odds
```

```{r}
# odds -> peluang dengan `odds/(odds+1)`
odds/(odds+1)
```

Terdapat cara lain:

* `logit()`: peluang -> log of odds
* `inv.logit()`: log of odds -> peluang

```{r}
library(gtools)

# peluang -> log of odds dengan `logit()`
logit(0.8)
```

```{r}
# log of odds -> peluang dengan `inv.logit()`
inv.logit(1.386294)
```

Fungsi `inv.logit()` ini juga biasa disebut *sigmoid function*.

```{r}
# sigmoid function
curve(inv.logit(x), from = -10, to = 10, 
      xlab = "Log of Odds", 
      ylab = "Peluang")
```
Logistic Regression:

- prediksi biner 
+ interpretable    
- non-robust

## `glm()` & Interpretation

Anda adalah seorang analis performa student di universitas. Anda ditugaskan untuk memprediksi status kelulusan siswa dengan honors (cumlaude).

```{r}
# read & inspect data
honors <- read.csv("data_input/sample.csv") %>% 
  select(-femalexmath)

glimpse(honors)
```

Deskripsi kolom:

* `female`: gender of student (1 for female)
* `read`: score in reading test
* `write`: score in writing test
* `math`: score in math test
* `hon`: status of graduating in honors (1 for honors)

```{r}
# cek missing value
anyNA(honors)
colSums(is.na(honors))
```

```{r}
# utk klasifikasi, target variable harus bertipe factor
# data wrangling base
honors$hon <- as.factor(honors$hon)
honors$female <- as.factor(honors$female)

library(dplyr) # memudahkan data wrangling/pre-processing/cleaning
# piping untuk menyambungkan proses, shortcut: ctrl + shift m
honors <- honors %>%
  # mengubah tipe data/isi kolom
  mutate(hon = as.factor(hon),
         female = as.factor(female))
```

```{r}
str(honors)
```

Cara membuat model logistic regression:

`glm(target ~ prediktor, data, family = "binomial")`

### Tanpa Prediktor

```{r}
# generalized linear model
honors.logit <- glm(formula = hon ~ 1, # satu, karena tanpa prediktor
                    data = honors, 
                    family = "binomial") # karena prediksi biner (2 kelas)

summary(honors.logit)
```

**Intercept**: log of odds dari target (student mendapatkan honors (1))

Berikut pembuktiannya:

```{r}
# peluang
table(honors$hon)
```

```{r}
# log of odds student honors
logit(49/(151+49))
```

**Interpretasi**: Log of odds tidak dapat diinterpretasikan. Untuk interpretasi, nilai log of odds kita ubah ke odds.

```{r}
# log of odds -> odds
exp(-1.12546)
```
Kejadian seseorang lulus kuis adalah **4 KALI lebih mungkin** dibandingkan tidak lulus kuis. 

> Kejadian seseorang mendapatkan honors 0.32 KALI lebih mungkin dibandingkan yang tidak honors

> Kejadian seseorang mendapatkan honors lebih tidak mungkin dibandingkan tidak honors (karena oddsnya < 1)

### 1 Prediktor Kategorik

Buat model untuk memprediksi `honors` berdasarkan gender `female`:

```{r}
honors.logit2 <- glm(formula = hon ~ female, data = honors, family = "binomial")
summary(honors.logit2)
```

**Female**: log of *odds ratio* dari student female mendapatkan honors dibandingkan student male mendapatkan honors.

```{r}
# proportion
table(female = honors$female, honors = honors$hon)
```

```{r}
# peluang
p_female <- 32/(77+32)
p_male <- 17/(17+74)

# odds 
o_female <- p_female/(1-p_female)
o_male <- p_male/(1-p_male)

# log of odds
log(o_female/o_male)
```

**Intercept**: log of odds dari student male yang mendapatkan honors (basis)

```{r}
log(o_male)
```

**Interpretasi:**

```{r}
# odds female dapat honors
exp(0.5928)
```

> Kejadian student female mendapatkan honors 1.8 KALI lebih mungkin dibandingkan student male mendapatkan honors

> Kejadian student female mendapatkan honors lebih mungkin dibantdingkan male mendapatkan honors

### 1 Prediktor Numerik

Buat model untuk memprediksi `honors` berdasarkan nilai `math`:

```{r}
honors.logit3 <- glm(formula = hon ~ math, data = honors, family = "binomial")
summary(honors.logit3)
```

**Intercept**: log of odds student honor yang nilai matematikanya 0

**Math**: peningkatan log of odds student honors setiap kenaikan 1 poin nilai math

Contoh: 

`hon = -9.79394 + 0.15634 * math`

Student A memiliki nilai math 52, student B 53. Hitung masing-masing log of oddsnya, berapa selisihnya?

```{r}
# hint: substitusi formula model saja
# log of odds
hon52 <- -9.79394 + 0.15634 * 52  
hon53 <- -9.79394 + 0.15634 * 53

hon53-hon52 # ini masih log of odds
```

**Interpretasi:**

```{r}
# log of odds -> odds
exp(0.15634)
```

> Kejadian student dengan nilai math 53 mendapatkan honors itu 1.17 KALI lebih mungkin dibandingkan student dengan nilai math 52 (1 poin di bawahnya)

> Semakin tinggi nilai matematika akan meningkatkan peluang student mendapatkan honors

> Setiap kenaikan nilai math 1 point memperbesar kemungkinan mendapatkan honors 1.17 KALI

### Banyak Prediktor

Buat model untuk memprediksi `honors` berdasarkan  gender `female` dan nilai `math`:

```{r}
honors.logit4 <- glm(hon ~ female + math, data = honors, family = "binomial")
summary(honors.logit4)
```

**Interpretasi koefisien:**

cari odds dari masing masing predictor:

```{r}
# female
exp(0.96531)
# math
exp(0.16422)
```

`female` = 2.63

> Kejadian student female mendapatkan honors 2.63 KALI lebih mungkin dibandingkan student male mendapatkan honors **dengan catatan** variable lain memiliki nilai yang sama

`math` = 1.18

> Setiap kenaikan nilai math 1 point memperbesar kemungkinan mendapatkan honors 1.18 KALI **dengan catatan** variable lain memiliki nilai yang sama

Yang dimaksud dengan variable lain memiliki nilai yang sama: misal sama-sama female,

Nabiilah
F - 60

Ina
F - 61

Tapi bila disimpulkan sederhana:

> menjadi female mingkatkan peluang mendapatkan honors
> memiliki nilai math lebih tinggi meningkatakn peluang mendapatkan honors

**Aplikasi:**

Final formula: -10.80595 + 0.96531 * female + 0.16422 * math

1. Husain adalah seorang male yang nilai math-nya 60, berapa peluang dia mendapatkan honors? Apakah dia akan lulus dengan honors?

```{r}
# log of odds
lo_husain <- -10.80595 + 0.96531 * 0 + 0.16422 * 60
lo_husain
```

```{r}
# peluang 
inv.logit(lo_husain)
```

Jawaban:

2. Nabiilah adalah seorang female dan nilai math-nya 80, berapa peluang dia mendapatkan honors? Apakah dia akan lulus dengan honors?

```{r}
# log of odds
lo_nabilah <- -10.80595 + 0.96531 * 1 + 0.16422 * 80
lo_nabilah
```

```{r}
# peluang 
inv.logit(lo_nabilah)
```

nabilah berpeluang 96% dapat honors

Jawaban:

Bonus! Apa yang harus dilakukan Husain agar ia dapat lulus dengan predikat honors? ...

```{r}

ifelse((-10.80595 + 0.96531 * 0 + 0.16422 * 69)>0.5,"LULUS","TIDAK")
```

minimal nilai matematika husain adalah 69 untuk memungkinkan mendapat honors

**Cara Prediksi Manual:**

```{r}
# log of odds (contoh untuk model honors.logit3, student dengan nilai math 52)
hon52
```
```{r}
# peluang
# gunakan inv.logit() dari package gtools untuk mengubah log of odds -> peluang
inv.logit(hon52)
```

```{r}
# klasifikasi; set threshold 0.5
ifelse(0.159191 > 0.5, "honors", "non-honors")
```

**Summary:**

1. Logistic regression menghasilkan log of odds
  - fungsi: `glm(formula = y ~ x, data, family = "binomial")`
  - binomial karena memprediksi 2 kelas (binary classification)

2. Untuk interpretasi model logistic regression,

- dilakukan: log of odds -> odds
- menggunakan fungsi: exp()

Interpretasi koefisien dapat dilakukan dan berbeda untuk masing-masing kondisi: 

- tanpa prediktor
- 1 prediktor kategorik
- 1 prediktor numerik
- banyak prediktor

Bila koefisien variable:

- positif: meningkatkan peluang
- negatif: menurunkan peluang

3. Untuk menentukan kelas (klasifikasi) dari hasil logistic regression, nilai *log of odds* diubah kebentuk *peluang* kemudian ditentukan kelasnya berdasarkan batas tertentu (misal = 0.5).

**END OF DAY 1**
---

## Model Selection

```{r}
summary(honors.logit4)
```

### AIC

AIC = Jumlah informasi yang hilang. Semakin kecil AIC, semakin baik model.

```{r}
honors.logit$aic # wo/ predictor
honors.logit2$aic # w/ female
honors.logit3$aic # w/ math
honors.logit4$aic # w/ female + math
```

### Perfect Separation

* **Null deviance**: deviasi model saat tanpa prediktor (model terburuk).
* **Residual deviance**: deviasi model saat menggunakan prediktor.

Umumnya semakin banyak prediktor maka residual deviance akan semakin kecil.

```{r}
# null deviance
honors.logit$null.deviance
```

```{r}
# residual deviance
honors.logit$deviance # wo/ predictor
honors.logit2$deviance # w/ female
honors.logit3$deviance # w/ math
honors.logit4$deviance # w/ female + math
```

Mari buat model `honors.logit5` untuk memprediksi `honors` berdasarkan semua prediktor yang ada:

```{r message=TRUE, warning=TRUE}
honors.logit5 <- glm(formula = hon ~ . , data = honors, family = "binomial")
honors.logit5
```

NOTE: 

* *glm.fit: fitted probabilities numerically 0 or 1 occurred* -> warning bahwa bisa dihasilkan probability yang tepat 1 atau 0 (indikasi kondisi **perfect separation**)
* *glm.fit: algorithm did not converge* -> warning bahwa algoritmanya tidak mencapai kondisi stabil hingga iterasi ke-25 (default), dapat terjadi salah satunya karena kondisi **perfect separation**.

**Perfect Separation** adalah sebuah kondisi dimana ada 1 variabel yang dapat memisahkan kelas target secara sempurna. Cara mendeteksi:

* bintang hilang, tidak ada variable yg signifikan
* variable write memiliki koefisien sangat besar sehingga akan sangat mempengaruhi result dan berpotensi menjadikan perfect separation
* aic sangat kecil
* residual deviance sangat kecil menandakan perfect separation

perfect separation membuat model sangat bias

```{r}
# log of odds -> odds
exp(36.30917)
```

Pada kasus ini, nilai write dapat memisahkan kelas honor dengan sempurna:

```{r}
table(honors$hon, honors$write)
```

```{r}
plot(honors$hon, honors$write)
```

> Tidak disarankan menggunakan model dengan perfect separation, karena model amat bias pada salah satu variable dan tidak mempertimbangkan variable lain. Hal ini dapat membuat model tidak akurat (buruk) dalam memprediksi ke data baru.

Apa yang kita lakukan bila bertemu kondisi perfect separation:

* kalau kasus seperti ini kita terima, tidak usah membuat machine learning, cukup `ifelse` saja.
* kalau kasus ini tidak kita terima, maka jangan gunakan variabel ini sebagai prediktor.
* observasi (data) nya kita tambah

```{r}
# revisi model

head(honors, n=10)
honors.logit6 <- glm(formula = hon ~ female + read+ math, data = honors, family = 'binomial' )
summary(honors.logit6 )


```

**Important Notes:**

Dalam menseleksi model, model yang baik adalah:

* model dengan nilai AIC rendah
* model tanpa kondisi Perfect Separation

## Assumption

Logistic Regression menganut 3 asumsi:

* **Linearity of Predictor & Log of Odds**: cara interpretasi model mengacu pada asumsi ini (contoh: untuk variabel numerik, peningkatan 1 nilai akan meningkatkan log of odds)
* **Multicollinearity**: antar prediktor tidak saling berkorelasi kuat (hingga nilai 1 / -1) -> uji `vif()`
* **Independence of Observations**: antar observasi saling independen & tidak berasal dari pengukuran berulang (repeated measurement) -> kita harus ambil data secara random sampling

Asumsi logistic regression menuntut kita untuk memahami data secara mendalam dan memastikan data sudah siap dipakai untuk membuat model. Coba analisis kasus di bawah:

**Dive Deeper**

Berikut data penerbangan pesawat dalam `flight_sm.csv`:

```{r}
flight <- read.csv("data_input/flight_sm.csv") %>% 
  mutate(DepDel15 = as.factor(DepDel15))
glimpse(flight)
str(flight)
```

Dekspripsi kolom:

* `Year, Month, DayofMonth, DayofWeek`: self-explanatory
* `Carrier`: maskapai
* `CRSDepTime & CRSArrTime`: jadwal departure & arrival (hhmm)
* `DepDel15`: status delay (1 = delay)
* `OriginState, DestState`: lokasi keberangkatan & tujuan

Buat model `flight.model` untuk memprediksi `DepDel15` berdasarkan `Month` + `DayofWeek`, kemudian tampilkan summary-nya:

```{r}
flight.model <- glm(formula = DepDel15 ~ Month + DayofWeek , data = flight, family = "binomial")
summary(flight.model)  
```

Perhatikan model dan analisis:

1. Interpretasi koefisien tiap variabel!

```{r}
exp(-0.060895)
inv.logit(-0.060895)

exp(-0.004576)
inv.logit(-0.004576)
```

* kejadian pesawat lebih delay 1 poin dari bulan sebelumnya adalah 0,94x lebih mungkin
* kejadian pesawat lebih delay 1 poin dari hari sebelumnya adalah 0,99x lebih mungkin

2. Apakah terdapat kesalahan dalam pembuatan model tersebut (cek bagian asumsi)?

```{r}
library(car)

vif(flight.model)
```

Note:
> asumsi Multicollinearity terpenuhi


3. Bila terdapat kesalahan, bagian mana? Apa yang harus dilakukan untuk memperbaiki model?
  
```{r}
flight$DayofMonth <- as.factor(flight$DayofMonth)
flight$Month <- as.factor(flight$Month)
flight.model <- glm(formula = DepDel15 ~ Month + DayofWeek , data = flight, family = "binomial")
summary(flight.model) 

unique(flight$Month)
```

> kejadian delay pesawat pada bulan 6 adalah 1,4x lebih mungkin dibanding bulan 4 (nilai intercept (karena bulan 4 ada di unique value tapi tidak ada di koefisien, makanya bulan 4 jadi intercept)) dengan catatan day of week nya sama
> bulan ke 6 memiliki kejadian delay paling mungkin karena memiliki koefisien terbesar 

# Classification Workflow

1. Business Question
2. Read Data
3. Data Wrangling
4. EDA
5. Cross Validation
6. Data Pre-Processing
7. Build Model
8. Predict
9. Model Evaluation
10. Model Tuning -> Final Model

**Studi Kasus: Credit Risk Analysis**

Buat model untuk memprediksi peluang customer akan gagal bayar pinjaman (loan default), untuk mengindikasikan apakah customer tersebut baik atau tidak untuk diberikan pinjaman.


###Business Question
identifikasi pengajuan pinjaman akan gagal bayar atau tidak

### Read Data

```{r}
loans <- read.csv("data_input/loan2017Q4.csv", stringsAsFactors = T)
```

### Data Wrangling

```{r}
glimpse(loans)
```

Target: not_paid (paid = 0, not_paid = 1)

- initial_list_status: Either w (whole) or f (fractional). This variable indicates if the loan was a whole loan or fractional loan. For background: Some institutional investors have a preference to purchase loans in their entirety to obtain legal and accounting treatment specific to their situation - with the added benefit of “instant funding” to borrowers
- purpose: Simplified from the original data; One of: credit_card, debt_consolidation, home_improvement, major_purchase and small_business
- int_rate: Interest rate in percentages
- installment: Monthly payment owed by the borrower
- annual_inc: Self-reported annual income provided by the borrower / co-borrowers during application
- dti: A ratio of the borrower’s total monthly debt payments on his/her total obligations to the self-reported monthly income
- verification_status: is the reported income verified, not verified, or if the income source was verified
- grade: software-assigned loan grade
- revol_bal: total credit revolving balance (in the case of credit card, it refers to the portion of credit card spending that goes unpaid at the end of a billing cycle)
- inq_last_12m: number of credit inquiries in the last 12 months
- delinq_2yrs: number of 30+ days past-due incidences of delinquency in the borrower’s credit file for the past 2 years
- home_ownership: one of MORTGAGE, OWN and RENT
- not_paid: 0 for fully-paid loans, 1 for charged-off, past-due / grace period or defaulted
- log_inc: log of annual_inc
- verified: 0 for “Not verified” under verification_status, 1 otherwise
- grdCtoA: 1 for a grade of A, B or C, 0 otherwise


Adakah variabel yang tipe datanya belum sesuai?

* not paid as factor
* verified as factor
* grdCtoA as factor

Adakah variabel yang dapat dibuang?

* grdCtoA -> reduntdant terhadap grade
* verification status -> simplifikasi dari verified
* log income

```{r}
loans <- loans %>%
  select(-c(grdCtoA, verification_status, log_inc)) %>%
  mutate(
    not_paid = as.factor(not_paid),
    verified = as.factor(verified)
  )

glimpse(loans)
```

### Exploratory Data Analysis

**Cek missing value**

```{r}
colSums(is.na(loans))
```

**Cek persebaran/pattern data**

```{r}
# explore with summary
summary(loans)
```

Insight: delinq_2yrs punya distribusi sempit, skewed ke kiri

Literature: Higher debt-to-income ratio (dti) and amount of credit card debts are both associated with a greater likelihood of loan defaults.

```{r}
# numeric predictor vs target variable
plot(loans$not_paid, loans$dti)
```

Insight: dti tidak jauh berbeda untuk not_paid(1) atau paid (0) namun bila secara bisnis berpengaruh maka sebaiknya dimasukkan ke prediktor.

**Cek class-imbalance** 

```{r}
table(loans$not_paid)
```

Proporsi yang seimbang penting agar model dapat mempelajari karakteristik kelas positif maupun negatif secara seimbang, tidak belajar dari satu kelas saja. Hal ini mencegah model dari *hanya baik memprediksi 1 kelas saja*. 

Proporsi yang imbalance umumnya 90/10 atau 95/5.

Kalau datanya imbalance:

- tambah data
- downSampling -> buang observasi dari kelas mayoritas, sehingga seimbang
- upSampling -> duplicate observasi dari kelas minoritas, sehingga seimbang

akan dipelajari di C2

### Cross Validation

- split data menjadi 2 bagian yaitu **data train** dan **data test**. 
- data train akan digunakan untuk training model.
- data test akan digunakan untuk pengujian performa model. model akan diuji untuk memprediksi data test. hasil prediksi dan data aktual dari data test akan dibandingkan untuk validasi performa model.

Analogi:

* 100 soal
* 80 soal saya pakai untuk belajar (data train)
* 20 soal saya pakai untuk ujian (data test)

tujuan dari cross validation adalah untuk mengetahui seberapa baik model yg sudah kita buat.

```{r}
# # intuisi set seed: mengunci random number kita
 set.seed(417) # pakai set.seed -> random number dikunci, hasil sampling selalu sama
 sample(c("Janu", "Kiki", "Sayyid", "Ani"), 2)
```

```{r}
RNGkind(sample.kind = "Rounding") # tambahan khusus u/ R 3.6 ke atas 
set.seed(417) # mengunci random number yang dipilih
# index sampling
index<-sample(nrow(loans), nrow(loans)*0.8)

# splitting
loans.train <- loans[index,] 
loans.test <- loans[-index,]
```

NOTE: Proporsi 0.8/0.2 tidak mutlak, tergantung kebutuhan kita. Umumnya yang lebih banyak adalah untuk data train.

```{r}
# re-check class imbalance
table(loans.train$not_paid)
table(loans.test$not_paid)
```

proporsi kelas yang balance penting untuk data train karena kita akan melatih model menggunakan data train.

### Build Model

Buatlah model logistic regression untuk memprediksi status loan (not_paid). Silahkan lakukan feature selection berdasarkan pertimbangan bisnis atau/dan statistik!

```{r}
head(loans.train, n=10)
```


```{r}
#model.loans <- glm(formula = not_paid ~ installment+annual_inc+delinq_2yrs+grade, data = loans.train, family = "binomial")
#summary(model.loans)  

model.loans <- glm(formula = not_paid ~ . , data = loans.train, family = "binomial")
summary(model.loans) 

#menyederhanakan model & mencari prediktor yg signifikan
model.step <- step(model.loans, direction = "backward", trace = T)
summary(model.step)
```


```{r}

```

Pilih masing-masing 1 untuk prediktor kategorik dan prediktor numerik, kemudian interpretasikan:

```{r}
# numerik:


# kategorik:

```

> ...

> ...

### Predict

`predict(model, newdata, type)`

pada `type` terdapat pilihan:

* link: menghasilkan log of odds
* response: menghasilkan peluang

Prediksi log of odds `not_paid` untuk 6 data teratas:

```{r}
predict(object = model.step , 
        newdata = loans.test[1:6,], 
        type = "link")


```

Prediksi probability `not_paid` untuk 6 data teratas:

```{r}
predict(object = model.step , 
        newdata = loans.test[1:6,], 
        type = "response")

#response menghasilkan peluang customer gagal bayar
```

**Dive Deeper**

Lakukan prediksi probability `not_paid` untuk data loans.test dan disimpan pada kolom baru bernama `pred.Risk`.

```{r}
loans.test$pred.Risk<-predict(object = model.step , 
        newdata = loans.test, 
        type = "response")

loans.test

#membuat kolom risk scoring berdasarkan model
```

Klasifikasikan data loans.test berdasarkan `pred.Risk` dan simpan pada kolom baru bernama `pred.Label`.

```{r}
# ifelse(kondisi, benar, salah)
loans.test$pred.Label <- ifelse(loans.test$pred.Risk > 0.5, 1, 0)
# pastikan kelas target (aktual dan prediksi) bertipe factor
loans.test$pred.Label <- as.factor(loans.test$pred.Label)

loans.test
```

pred label berlinai 0/1 karena akan menyamakan dengan not paid supaya akan dipakai di proses model evaluation

**Note:**

Penentuan label yang menjadi angka 1 pada **model logistic regression** adalah berdasarkan levels.

kelas "0", "1" -> basis = 0, 
                  peluang mendekati 0 -> 0
                  peluang mendekati 1 -> 1

kelas "honors" "non-honors" -> basis = honors
                            peluang mendekati 0 -> honors
                            peluang mendekati 1 -> non-honors

```{r}
# lihat hasil prediksi
loans.test %>% 
  select(not_paid, pred.Risk, pred.Label) %>% 
  head(6)
```

**Summary**

1. Seleksi model logistic regression:

- ...
- ...

2. Asumsi model logistic regression:

- ...
- ...
- ...

3. Workflow klasifikasi:
 
* ...
* ...
* ...

